"""
Generate Embeddings Script
===========================
Batch process to generate embeddings for all ai_documents rows.
Run this once after deploying the embeddings service.

IMPORTANT: This script must be run via MCP tool (mcp_supabase_execute_sql) 
because it requires database write permissions that the REST API anon key doesn't have.

Usage:
    python scripts/generate_embeddings.py
"""

import sys
import json
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.embedding_service import get_embeddings_service
from app.services.supabase_client import get_supabase
from app.utils.logger import logger


def generate_embeddings_sql():
    """
    Generate embeddings and return SQL statements for batch update.
    This approach avoids REST API permission issues by using direct SQL.
    """
    
    logger.info("Starting embedding generation process...")
    
    # Initialize services
    embeddings_service = get_embeddings_service()
    supabase = get_supabase()
    
    # Get model info
    model_info = embeddings_service.get_model_info()
    logger.info(f"Model: {model_info['model_name']}")
    logger.info(f"Device: {model_info['device']}")
    logger.info(f"Embedding dimension: {model_info['embedding_dim']}")
    
    # Fetch documents without embeddings
    logger.info("Fetching documents without embeddings...")
    
    try:
        # Query documents where embedding is NULL
        response = supabase.get_safe(
            "ai_documents?select=id,searchable_text&embedding=is.null&limit=10000",
            default=[]
        )
        
        docs = response if isinstance(response, list) else []
        total_docs = len(docs)
        
        if total_docs == 0:
            logger.success("All documents already have embeddings!")
            return None
        
        logger.info(f"Found {total_docs} documents without embeddings")
        
        # Process in batches
        batch_size = 100
        all_updates = []
        
        for i in range(0, total_docs, batch_size):
            batch = docs[i:i+batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (total_docs + batch_size - 1) // batch_size
            
            logger.info(f"Processing batch {batch_num}/{total_batches} ({len(batch)} documents)...")
            
            try:
                # Extract texts
                texts = [doc.get('searchable_text', '') for doc in batch]
                
                # Generate embeddings in batch
                embeddings = embeddings_service.batch_encode(texts, is_query=False)
                
                # Prepare update statements
                for doc, embedding in zip(batch, embeddings):
                    doc_id = doc.get('id')
                    
                    if not doc_id:
                        logger.warning(f"Document missing ID, skipping")
                        continue
                    
                    # Convert embedding to PostgreSQL array format
                    embedding_str = '[' + ','.join(map(str, embedding)) + ']'
                    all_updates.append((doc_id, embedding_str))
                
                # Progress update
                progress_pct = ((i + len(batch)) / total_docs) * 100
                logger.info(f"Progress: {len(all_updates)}/{total_docs} ({progress_pct:.1f}%)")
                
            except Exception as e:
                logger.error(f"Error processing batch {batch_num}: {e}")
        
        # Generate SQL for batch update
        if all_updates:
            logger.info(f"Generated {len(all_updates)} embedding updates")
            logger.info("Writing SQL update file...")
            
            # Write SQL file
            sql_file = Path(__file__).parent.parent / "embedding_updates.sql"
            with open(sql_file, 'w') as f:
                f.write("-- Batch update embeddings for ai_documents\n")
                f.write("-- Generated by generate_embeddings.py\n\n")
                
                for doc_id, embedding_str in all_updates:
                    f.write(f"UPDATE ai_documents SET embedding = '{embedding_str}'::vector WHERE id = '{doc_id}';\n")
            
            logger.success(f"SQL file written to: {sql_file}")
            logger.info(f"Total updates: {len(all_updates)}")
            logger.info("To apply updates, run the SQL file via MCP or psql")
            
            return str(sql_file)
        else:
            logger.warning("No updates generated")
            return None
        
    except Exception as e:
        logger.error(f"Fatal error in embedding generation: {e}")
        raise


def generate_embeddings():
    """Legacy function - calls SQL-based approach."""
    return generate_embeddings_sql()


if __name__ == "__main__":
    try:
        generate_embeddings()
    except KeyboardInterrupt:
        logger.warning("Process interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Script failed: {e}")
        sys.exit(1)
