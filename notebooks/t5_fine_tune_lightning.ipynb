{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfaf T5 Fine-Tuning \u2014 AU-Ggregates Text-to-SQL (Lightning AI)\n",
    "\n",
    "Fine-tunes `gaussalgo/T5-LM-Large-text2sql-spider` on your custom + Spider training data.\n",
    "\n",
    "## Before you start\n",
    "1. Create a new Studio on [lightning.ai](https://lightning.ai) with **GPU** (L4 recommended, 24GB VRAM)\n",
    "2. Upload your `t5_text2sql_5000_pairs.jsonl` file to the studio file browser\n",
    "3. Open this notebook and run all cells\n",
    "\n",
    "## Pipeline\n",
    "| Step | Cell | What it does | Time |\n",
    "|------|------|-------------|------|\n",
    "| 1 | Install | Install dependencies | ~2 min |\n",
    "| 2 | GPU Check | Verify GPU | instant |\n",
    "| 3 | Load Data | Point to uploaded JSONL file | instant |\n",
    "| 4 | Validate | Validate all 5,000 pairs | ~10 sec |\n",
    "| 5 | Clean + Merge | Clean custom pairs + merge Spider data | ~3-5 min |\n",
    "| 6 | Train | Fine-tune T5 (10 epochs) | ~45-90 min |\n",
    "| 7 | Evaluate | Test accuracy on validation set | ~5 min |\n",
    "| 8 | Test | Interactive SQL generation test | instant |\n",
    "| 9 | Export | Zip model for download | ~2 min |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 1: Install dependencies\n",
    "# ============================================================\n",
    "!pip install -q torch transformers accelerate sentencepiece\n",
    "!pip install -q datasets evaluate sqlparse\n",
    "!pip install -q huggingface_hub\n",
    "\n",
    "print('\\n\u2705 All dependencies installed!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 2: Verify GPU\n",
    "# ============================================================\n",
    "import torch\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA:    {torch.cuda.is_available()}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.get_device_name(0)\n",
    "    vram = torch.cuda.get_device_properties(0).total_mem / 1024**3\n",
    "    print(f'GPU:     {gpu} ({vram:.1f} GB VRAM)')\n",
    "    print('\u2705 GPU ready!')\n",
    "else:\n",
    "    print('\u274c No GPU! Create a new Studio with GPU enabled.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 3: Load training data\n",
    "# ============================================================\n",
    "# Upload your JSONL file to the Lightning AI file browser first,\n",
    "# then set the path below.\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Set your file path here ---\n",
    "# Lightning AI default workspace: /teamspace/studios/this_studio/\n",
    "TRAINING_FILE = '/teamspace/studios/this_studio/t5_text2sql_5000_pairs.jsonl'\n",
    "\n",
    "# Auto-detect: check common locations\n",
    "if not os.path.exists(TRAINING_FILE):\n",
    "    candidates = [\n",
    "        '/teamspace/studios/this_studio/t5_text2sql_5000_pairs.jsonl',\n",
    "        '/home/zeus/t5_text2sql_5000_pairs.jsonl',\n",
    "        './t5_text2sql_5000_pairs.jsonl',\n",
    "        'data/t5_text2sql_5000_pairs.jsonl',\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if os.path.exists(c):\n",
    "            TRAINING_FILE = c\n",
    "            break\n",
    "\n",
    "if os.path.exists(TRAINING_FILE):\n",
    "    size_mb = os.path.getsize(TRAINING_FILE) / 1024 / 1024\n",
    "    print(f'\u2705 Found: {TRAINING_FILE} ({size_mb:.1f} MB)')\n",
    "else:\n",
    "    print(f'\u274c File not found: {TRAINING_FILE}')\n",
    "    print('   Upload your JSONL file to the file browser and update the path above.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 4: Validate training data\n",
    "# ============================================================\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "SCHEMA_PREFIX = 'tables: ai_documents (id, source_table, file_name, project_name, searchable_text, metadata, document_type) | query:'\n",
    "VALID_SOURCE_TABLES = {'Expenses', 'CashFlow', 'Project', 'Quotation', 'QuotationItem'}\n",
    "NUMERIC_KEYS = {'Expenses', 'Amount', 'total_amount', 'volume', 'line_total'}\n",
    "\n",
    "pairs = []\n",
    "errors = []\n",
    "source_table_counts = Counter()\n",
    "intent_counts = Counter()\n",
    "\n",
    "with open(TRAINING_FILE, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            pair = json.loads(line)\n",
    "        except json.JSONDecodeError as e:\n",
    "            errors.append(f'Line {i}: Invalid JSON - {e}')\n",
    "            continue\n",
    "\n",
    "        inp = pair.get('input', '')\n",
    "        tgt = pair.get('target', '')\n",
    "\n",
    "        if 'input' not in pair or 'target' not in pair:\n",
    "            errors.append(f'Line {i}: Missing input or target key')\n",
    "            continue\n",
    "\n",
    "        if not inp.startswith(SCHEMA_PREFIX):\n",
    "            errors.append(f'Line {i}: Missing Spider schema prefix')\n",
    "\n",
    "        tgt_upper = tgt.strip().upper()\n",
    "        if not tgt_upper.startswith('SELECT'):\n",
    "            errors.append(f'Line {i}: Target is not a SELECT statement')\n",
    "\n",
    "        has_source = any(f\"source_table = '{t}'\" in tgt for t in VALID_SOURCE_TABLES)\n",
    "        if not has_source:\n",
    "            errors.append(f'Line {i}: Missing source_table filter')\n",
    "\n",
    "        if \"document_type = 'file'\" not in tgt and \"document_type = 'row'\" not in tgt:\n",
    "            errors.append(f'Line {i}: Missing document_type filter')\n",
    "\n",
    "        for t in VALID_SOURCE_TABLES:\n",
    "            if f\"source_table = '{t}'\" in tgt:\n",
    "                source_table_counts[t] += 1\n",
    "\n",
    "        if 'SUM(' in tgt_upper:\n",
    "            intent_counts['sum'] += 1\n",
    "        elif 'AVG(' in tgt_upper:\n",
    "            intent_counts['average'] += 1\n",
    "        elif 'COUNT(' in tgt_upper:\n",
    "            intent_counts['count'] += 1\n",
    "        elif 'GROUP BY' in tgt_upper and ('SUM' in tgt_upper or 'COUNT' in tgt_upper):\n",
    "            intent_counts['compare'] += 1\n",
    "        elif 'DISTINCT' in tgt_upper:\n",
    "            intent_counts['list_categories'] += 1\n",
    "        elif \"document_type = 'file'\" in tgt:\n",
    "            intent_counts['list_files'] += 1\n",
    "        else:\n",
    "            intent_counts['query_data'] += 1\n",
    "\n",
    "        pairs.append(pair)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'\ud83d\udcca VALIDATION REPORT')\n",
    "print('=' * 60)\n",
    "print(f'Total pairs:  {len(pairs)}')\n",
    "print(f'Errors:       {len(errors)}')\n",
    "print()\n",
    "print('Source table distribution:')\n",
    "for t in sorted(source_table_counts, key=source_table_counts.get, reverse=True):\n",
    "    pct = source_table_counts[t] / len(pairs) * 100\n",
    "    print(f'  {t:20s} {source_table_counts[t]:5d} ({pct:.1f}%)')\n",
    "print()\n",
    "print('Intent distribution:')\n",
    "for intent in sorted(intent_counts, key=intent_counts.get, reverse=True):\n",
    "    pct = intent_counts[intent] / len(pairs) * 100\n",
    "    print(f'  {intent:20s} {intent_counts[intent]:5d} ({pct:.1f}%)')\n",
    "print()\n",
    "\n",
    "if errors:\n",
    "    print(f'\u26a0\ufe0f  First 10 errors:')\n",
    "    for e in errors[:10]:\n",
    "        print(f'  {e}')\n",
    "    print()\n",
    "\n",
    "if len(pairs) >= 4500 and len(errors) < len(pairs) * 0.05:\n",
    "    print(f'\u2705 Data looks good! {len(pairs)} valid pairs ready.')\n",
    "elif len(pairs) > 0:\n",
    "    print(f'\u26a0\ufe0f  {len(pairs)} valid pairs. Error rate: {len(errors)/max(len(pairs),1)*100:.1f}%')\n",
    "else:\n",
    "    print('\u274c No valid pairs found! Check your JSONL file.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 5: Clean custom pairs + Merge with Spider dataset\n",
    "# ============================================================\n",
    "import json, re, hashlib, random\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "\n",
    "SPIDER_LIMIT = 3000\n",
    "\n",
    "def normalize_sql(sql):\n",
    "    sql = sql.strip().rstrip(';').strip()\n",
    "    sql = re.sub(r'\\\\s+', ' ', sql)\n",
    "    return sql.lower()\n",
    "\n",
    "def sql_fingerprint(pair):\n",
    "    return hashlib.md5(normalize_sql(pair.get('target', '')).encode()).hexdigest()\n",
    "\n",
    "TYPO_FIXES = {\n",
    "    \"source_table = 'expenses'\": \"source_table = 'Expenses'\",\n",
    "    \"source_table = 'cashflow'\": \"source_table = 'CashFlow'\",\n",
    "    \"source_table = 'Cashflow'\": \"source_table = 'CashFlow'\",\n",
    "    \"source_table = 'cash_flow'\": \"source_table = 'CashFlow'\",\n",
    "    \"source_table = 'project'\": \"source_table = 'Project'\",\n",
    "    \"source_table = 'quotation'\": \"source_table = 'Quotation'\",\n",
    "    \"source_table = 'quotationitem'\": \"source_table = 'QuotationItem'\",\n",
    "    \"source_table = 'QuotationItems'\": \"source_table = 'QuotationItem'\",\n",
    "    \"source_table = 'Quotation_Item'\": \"source_table = 'QuotationItem'\",\n",
    "}\n",
    "\n",
    "def clean_pair(pair):\n",
    "    tgt = pair['target'].strip()\n",
    "    if not tgt.endswith(';'):\n",
    "        tgt += ';'\n",
    "    tgt = tgt.replace(';;', ';')\n",
    "    for wrong, right in TYPO_FIXES.items():\n",
    "        tgt = tgt.replace(wrong, right)\n",
    "    tgt = re.sub(r\"metadata->'(\\\\w+)'\", r\"metadata->>'\\\\1'\", tgt)\n",
    "    pair['target'] = tgt\n",
    "    return pair\n",
    "\n",
    "def validate_custom(pair):\n",
    "    inp = pair.get('input', '')\n",
    "    tgt = pair.get('target', '')\n",
    "    if not inp.startswith(SCHEMA_PREFIX):\n",
    "        return False\n",
    "    if not tgt.strip().upper().startswith('SELECT'):\n",
    "        return False\n",
    "    has_src = any(f\"source_table = '{t}'\" in tgt for t in VALID_SOURCE_TABLES)\n",
    "    if not has_src:\n",
    "        return False\n",
    "    if \"document_type = 'file'\" not in tgt and \"document_type = 'row'\" not in tgt:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "print('\ud83e\uddf9 Step 1: Cleaning custom pairs...')\n",
    "cleaned = [clean_pair(dict(p)) for p in pairs]\n",
    "valid_custom = [p for p in cleaned if validate_custom(p)]\n",
    "n_invalid = len(cleaned) - len(valid_custom)\n",
    "print(f'   Valid: {len(valid_custom)}, Invalid: {n_invalid}')\n",
    "\n",
    "print(f'\\n\ud83d\udd77\ufe0f Step 2: Downloading Spider dataset (limit={SPIDER_LIMIT})...')\n",
    "spider_ds = load_dataset('spider', split='train', trust_remote_code=True)\n",
    "spider_pairs = []\n",
    "spider_seen = set()\n",
    "\n",
    "for ex in spider_ds:\n",
    "    q = ex.get('question', '')\n",
    "    sql = ex.get('query', '')\n",
    "    db = ex.get('db_id', '')\n",
    "    if not q or not sql:\n",
    "        continue\n",
    "    if not sql.strip().upper().startswith('SELECT'):\n",
    "        continue\n",
    "    tgt = sql.strip()\n",
    "    if not tgt.endswith(';'):\n",
    "        tgt += ';'\n",
    "    sfp = hashlib.md5(normalize_sql(tgt).encode()).hexdigest()\n",
    "    if sfp in spider_seen:\n",
    "        continue\n",
    "    spider_seen.add(sfp)\n",
    "    spider_pairs.append({'input': f'tables: {db} | query: {q}', 'target': tgt})\n",
    "    if len(spider_pairs) >= SPIDER_LIMIT:\n",
    "        break\n",
    "\n",
    "print(f'   Spider pairs loaded: {len(spider_pairs)}')\n",
    "\n",
    "print('\\n\ud83d\udd00 Step 3: Merging + deduplicating...')\n",
    "all_merged = valid_custom + spider_pairs\n",
    "seen_fps = set()\n",
    "deduped = []\n",
    "n_dupes = 0\n",
    "for p in all_merged:\n",
    "    fp = sql_fingerprint(p)\n",
    "    if fp not in seen_fps:\n",
    "        seen_fps.add(fp)\n",
    "        deduped.append(p)\n",
    "    else:\n",
    "        n_dupes += 1\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(deduped)\n",
    "\n",
    "MERGED_FILE = '/teamspace/studios/this_studio/training_final.jsonl'\n",
    "with open(MERGED_FILE, 'w', encoding='utf-8') as f:\n",
    "    for p in deduped:\n",
    "        f.write(json.dumps(p, ensure_ascii=False) + '\\n')\n",
    "\n",
    "TRAINING_FILE = MERGED_FILE\n",
    "\n",
    "print()\n",
    "print('=' * 60)\n",
    "print('  CLEAN + MERGE REPORT')\n",
    "print('=' * 60)\n",
    "print(f'  Custom pairs (valid):    {len(valid_custom)}')\n",
    "print(f'  Custom pairs (invalid):  {n_invalid}')\n",
    "print(f'  Spider pairs:            {len(spider_pairs)}')\n",
    "print(f'  Duplicates removed:      {n_dupes}')\n",
    "print(f'  Total merged:            {len(deduped)}')\n",
    "print('=' * 60)\n",
    "if len(deduped) >= 5000:\n",
    "    print(f'\u2705 {len(deduped)} pairs ready for training!')\n",
    "else:\n",
    "    print(f'\u26a0\ufe0f  Only {len(deduped)} pairs.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 6: Fine-tune T5\n",
    "# ============================================================\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_NAME = 'gaussalgo/T5-LM-Large-text2sql-spider'\n",
    "OUTPUT_DIR = '/teamspace/studios/this_studio/t5-finetuned'\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8          # L4 has 24GB VRAM, can handle batch_size=8\n",
    "LEARNING_RATE = 3e-5    # low LR for second-stage fine-tuning (prevents catastrophic forgetting)\n",
    "MAX_INPUT_LEN = 512\n",
    "MAX_TARGET_LEN = 256\n",
    "\n",
    "# --- Load data ---\n",
    "print('\ud83d\udcc2 Loading training data...')\n",
    "inputs, targets = [], []\n",
    "with open(TRAINING_FILE, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            pair = json.loads(line)\n",
    "            if 'input' in pair and 'target' in pair:\n",
    "                inputs.append(pair['input'])\n",
    "                targets.append(pair['target'])\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "dataset = Dataset.from_dict({'input': inputs, 'target': targets})\n",
    "split = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split['train']\n",
    "val_ds = split['test']\n",
    "print(f'   Train: {len(train_ds)}, Validation: {len(val_ds)}')\n",
    "\n",
    "# --- Load model ---\n",
    "print(f'\ud83e\udd16 Loading {MODEL_NAME}...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "print(f'   Parameters: {model.num_parameters():,}')\n",
    "\n",
    "# --- Tokenize ---\n",
    "def tokenize(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['input'], max_length=MAX_INPUT_LEN,\n",
    "        truncation=True, padding='max_length'\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples['target'], max_length=MAX_TARGET_LEN,\n",
    "        truncation=True, padding='max_length'\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "print('\ud83d\udd24 Tokenizing...')\n",
    "tok_train = train_ds.map(tokenize, batched=True, remove_columns=['input', 'target'])\n",
    "tok_val = val_ds.map(tokenize, batched=True, remove_columns=['input', 'target'])\n",
    "\n",
    "# --- Training args ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=2,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_train,\n",
    "    eval_dataset=tok_val,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True),\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "print(f'\\n\ud83d\ude80 Starting training: {EPOCHS} epochs, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}')\n",
    "print(f'   Steps per epoch: ~{len(tok_train) // BATCH_SIZE}')\n",
    "print(f'   Estimated time: ~{EPOCHS * len(tok_train) // BATCH_SIZE * 0.6 / 60:.0f} minutes on L4\\n')\n",
    "\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "elapsed = (time.time() - start) / 60\n",
    "\n",
    "# --- Save ---\n",
    "save_path = f'{OUTPUT_DIR}/final'\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f'\\n\u2705 Training complete in {elapsed:.1f} minutes!')\n",
    "print(f'   Model saved to: {save_path}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 7: Evaluate on validation set\n",
    "# ============================================================\n",
    "import sqlparse\n",
    "import time\n",
    "\n",
    "print('\ud83d\udcca Evaluating on validation set...\\n')\n",
    "\n",
    "model.eval()\n",
    "device = model.device\n",
    "\n",
    "exact_matches = 0\n",
    "valid_sql = 0\n",
    "total_time = 0.0\n",
    "samples = []\n",
    "\n",
    "for idx in range(len(val_ds)):\n",
    "    inp = val_ds[idx]['input']\n",
    "    expected = val_ds[idx]['target']\n",
    "\n",
    "    encoded = tokenizer(inp, return_tensors='pt', max_length=MAX_INPUT_LEN, truncation=True, padding=True)\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "    t0 = time.time()\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=MAX_TARGET_LEN)\n",
    "    total_time += (time.time() - t0) * 1000\n",
    "\n",
    "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    if generated == expected:\n",
    "        exact_matches += 1\n",
    "\n",
    "    try:\n",
    "        parsed = sqlparse.parse(generated)\n",
    "        if parsed and parsed[0].get_type() and parsed[0].get_type().upper() == 'SELECT':\n",
    "            valid_sql += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if len(samples) < 15:\n",
    "        match = '\u2705' if generated == expected else '\u274c'\n",
    "        samples.append((match, inp.split('query: ')[-1], expected, generated))\n",
    "\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f'  Evaluated {idx + 1}/{len(val_ds)}...')\n",
    "\n",
    "total = len(val_ds)\n",
    "em_acc = exact_matches / total * 100\n",
    "exec_acc = valid_sql / total * 100\n",
    "avg_ms = total_time / total\n",
    "\n",
    "print()\n",
    "print('=' * 60)\n",
    "print('  EVALUATION RESULTS')\n",
    "print('=' * 60)\n",
    "print(f'  Validation examples:   {total}')\n",
    "print(f'  Exact-match accuracy:  {em_acc:.1f}%')\n",
    "print(f'  Valid SQL rate:        {exec_acc:.1f}%')\n",
    "print(f'  Avg inference time:    {avg_ms:.1f} ms')\n",
    "print('=' * 60)\n",
    "print()\n",
    "\n",
    "if em_acc >= 70:\n",
    "    print('\ud83c\udf89 Great accuracy! Model is ready for deployment.')\n",
    "elif em_acc >= 50:\n",
    "    print('\ud83d\udc4d Decent accuracy. Consider more training data or epochs.')\n",
    "else:\n",
    "    print('\u26a0\ufe0f  Low accuracy. Check training data quality or try more epochs.')\n",
    "\n",
    "print()\n",
    "print('Sample predictions:')\n",
    "print('-' * 60)\n",
    "for match, question, expected, generated in samples[:10]:\n",
    "    print(f'{match} Q: {question}')\n",
    "    print(f'   Expected:  {expected[:100]}')\n",
    "    print(f'   Generated: {generated[:100]}')\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 8: Interactive test\n",
    "# ============================================================\n",
    "\n",
    "SCHEMA_PREFIX_Q = 'tables: ai_documents (id, source_table, file_name, project_name, searchable_text, metadata, document_type) | query: '\n",
    "\n",
    "def generate_sql(question):\n",
    "    full_input = SCHEMA_PREFIX_Q + question\n",
    "    encoded = tokenizer(full_input, return_tensors='pt', max_length=MAX_INPUT_LEN, truncation=True, padding=True)\n",
    "    input_ids = encoded.input_ids.to(model.device)\n",
    "    attention_mask = encoded.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=MAX_TARGET_LEN)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "test_questions = [\n",
    "    'show all expense files',\n",
    "    'what are the total fuel expenses',\n",
    "    'how many labor entries are in project alpha',\n",
    "    'total cash flow amount for highway 5',\n",
    "    'show approved quotations for manila tower',\n",
    "    'total volume delivered for plate ABC-1234',\n",
    "    'list all active projects',\n",
    "    'average expense amount for materials',\n",
    "    'how many deliveries used 10-wheeler trucks',\n",
    "    'compare fuel costs between manila tower and building c',\n",
    "]\n",
    "\n",
    "print('\ud83e\uddea Testing SQL generation:\\n')\n",
    "for q in test_questions:\n",
    "    sql = generate_sql(q)\n",
    "    print(f'Q: {q}')\n",
    "    print(f'\u2192 {sql}')\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 8B: Try your own question (edit and re-run)\n",
    "# ============================================================\n",
    "\n",
    "my_question = 'total expenses for SJDM project'  # <-- edit this!\n",
    "\n",
    "sql = generate_sql(my_question)\n",
    "print(f'Q: {my_question}')\n",
    "print(f'\u2192 {sql}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 9: Export model (zip for download)\n",
    "# ============================================================\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "FINAL_MODEL = '/teamspace/studios/this_studio/t5-finetuned/final'\n",
    "ZIP_OUTPUT = '/teamspace/studios/this_studio/t5-finetuned-model'\n",
    "\n",
    "print('\ud83d\udce6 Zipping model for download...')\n",
    "zip_path = shutil.make_archive(ZIP_OUTPUT, 'zip', FINAL_MODEL)\n",
    "print(f'   Size: {Path(zip_path).stat().st_size / 1024 / 1024:.0f} MB')\n",
    "print(f'   File: {zip_path}')\n",
    "print()\n",
    "print('\u2705 Model exported!')\n",
    "print('   Download the zip from the file browser on the left.')\n",
    "print('   Extract it and set T5_MODEL_PATH to the extracted folder.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 9B: Push to HuggingFace Hub (optional)\n",
    "# ============================================================\n",
    "# Uncomment and fill in your details to push to HF Hub\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login(token='YOUR_HF_TOKEN')\n",
    "#\n",
    "# HF_REPO = 'your-username/t5-auggregates-text2sql'  # <-- change this!\n",
    "#\n",
    "# model.push_to_hub(HF_REPO)\n",
    "# tokenizer.push_to_hub(HF_REPO)\n",
    "# print(f'\u2705 Pushed to https://huggingface.co/{HF_REPO}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcdd After Training\n",
    "\n",
    "**To use the fine-tuned model in production:**\n",
    "\n",
    "1. Download the zip from Cell 9 (use the file browser on the left)\n",
    "2. Extract to a folder on your server\n",
    "3. Set `T5_MODEL_PATH` environment variable to the extracted folder path\n",
    "4. The AI server will automatically use your fine-tuned model\n",
    "\n",
    "**Expected accuracy targets:**\n",
    "- Exact-match: 70%+ (good), 80%+ (great)\n",
    "- Valid SQL rate: 95%+\n",
    "\n",
    "**If accuracy is low:**\n",
    "- Check training data quality (run Cell 4 validation)\n",
    "- Try more epochs (change EPOCHS in Cell 6)\n",
    "- Try lower learning rate (1e-4 instead of 3e-4)\n",
    "- Add more diverse training pairs"
   ]
  }
 ]
}