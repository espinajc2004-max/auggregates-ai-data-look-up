{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "kaggle": {
   "accelerator": "gpu",
   "isGpuEnabled": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ T5 Fine-Tuning ‚Äî AU-Ggregates Text-to-SQL (Kaggle)\n",
    "\n",
    "Fine-tunes `gaussalgo/T5-LM-Large-text2sql-spider` on your custom + Spider training data.\n",
    "\n",
    "## Before you start\n",
    "1. Go to **Settings** (right panel) ‚Üí **Accelerator** ‚Üí select **GPU T4 x2** or **P100**\n",
    "2. Click **Add Data** (right panel) ‚Üí upload your `t5_text2sql_5000_pairs.jsonl`\n",
    "3. Your uploaded file will be at `/kaggle/input/YOUR_DATASET_NAME/t5_text2sql_5000_pairs.jsonl`\n",
    "\n",
    "## Pipeline\n",
    "| Step | Cell | What it does | Time |\n",
    "|------|------|-------------|------|\n",
    "| 1 | Install | Install dependencies | ~2 min |\n",
    "| 2 | GPU Check | Verify GPU | instant |\n",
    "| 3 | Load Data | Auto-find uploaded JSONL file | instant |\n",
    "| 4 | Validate | Validate all 5,000 pairs | ~10 sec |\n",
    "| 5 | Clean + Merge | Clean custom + Spider + b-mc2 adapted pairs | ~5-8 min |\n",
    "| 6 | Train | Fine-tune T5 (5 epochs, lr=3e-5) | ~30-60 min |\n",
    "| 7 | Evaluate | Test accuracy on validation set | ~5 min |\n",
    "| 8 | Test | Interactive SQL generation test | instant |\n",
    "| 9 | Export | Zip model for download | ~2 min |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 1: Install dependencies\n",
    "# ============================================================\n",
    "# CRITICAL: Must set BEFORE any torch import to prevent DataParallel NaN\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "!pip install -q transformers accelerate sentencepiece\n",
    "!pip install -q datasets evaluate sqlparse\n",
    "!pip install -q huggingface_hub peft\n",
    "\n",
    "print('\\nAll dependencies installed!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 2: Verify GPU\n",
    "# ==================================sa==========================\n",
    "import torch\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA:    {torch.cuda.is_available()}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    print(f'GPUs:    {n_gpus}')\n",
    "    for i in range(n_gpus):\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        vram = (getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)) / 1024**3\n",
    "        print(f'  GPU {i}: {name} ({vram:.1f} GB VRAM)')\n",
    "    print('\\n‚úÖ GPU ready!')\n",
    "else:\n",
    "    print('‚ùå No GPU! Go to Settings ‚Üí Accelerator ‚Üí GPU T4 x2')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 3: Load training data (auto-detect from /kaggle/input/)\n",
    "# ============================================================\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Auto-find the JSONL file in /kaggle/input/\n",
    "matches = glob.glob('/kaggle/input/**/*.jsonl', recursive=True)\n",
    "\n",
    "if matches:\n",
    "    TRAINING_FILE = matches[0]\n",
    "    print(f'üìÅ Found: {TRAINING_FILE}')\n",
    "    print(f'   Size: {os.path.getsize(TRAINING_FILE) / 1024 / 1024:.1f} MB')\n",
    "else:\n",
    "    print('‚ùå No JSONL file found in /kaggle/input/')\n",
    "    print('   Click \"Add Data\" in the right panel and upload your .jsonl file')\n",
    "    print()\n",
    "    print('   Available files in /kaggle/input/:')\n",
    "    for f in glob.glob('/kaggle/input/**/*', recursive=True):\n",
    "        print(f'     {f}')\n",
    "    TRAINING_FILE = None\n",
    "\n",
    "print(f'\\n‚úÖ TRAINING_FILE = {TRAINING_FILE}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 4: Validate training data\n",
    "# ============================================================\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "SCHEMA_PREFIX = 'tables: ai_documents (id, source_table, file_name, project_name, searchable_text, metadata, document_type) | query:'\n",
    "VALID_SOURCE_TABLES = {'Expenses', 'CashFlow', 'Project', 'Quotation', 'QuotationItem'}\n",
    "NUMERIC_KEYS = {'Expenses', 'Amount', 'total_amount', 'volume', 'line_total'}\n",
    "\n",
    "pairs = []\n",
    "errors = []\n",
    "source_table_counts = Counter()\n",
    "intent_counts = Counter()\n",
    "\n",
    "with open(TRAINING_FILE, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            pair = json.loads(line)\n",
    "        except json.JSONDecodeError as e:\n",
    "            errors.append(f'Line {i}: Invalid JSON - {e}')\n",
    "            continue\n",
    "\n",
    "        inp = pair.get('input', '')\n",
    "        tgt = pair.get('target', '')\n",
    "\n",
    "        if 'input' not in pair or 'target' not in pair:\n",
    "            errors.append(f'Line {i}: Missing input or target key')\n",
    "            continue\n",
    "\n",
    "        if not inp.startswith(SCHEMA_PREFIX):\n",
    "            errors.append(f'Line {i}: Missing Spider schema prefix')\n",
    "\n",
    "        tgt_upper = tgt.strip().upper()\n",
    "        if not tgt_upper.startswith('SELECT'):\n",
    "            errors.append(f'Line {i}: Target is not a SELECT statement')\n",
    "\n",
    "        has_source = any(f\"source_table = '{t}'\" in tgt for t in VALID_SOURCE_TABLES)\n",
    "        if not has_source:\n",
    "            errors.append(f'Line {i}: Missing source_table filter')\n",
    "\n",
    "        if \"document_type = 'file'\" not in tgt and \"document_type = 'row'\" not in tgt:\n",
    "            errors.append(f'Line {i}: Missing document_type filter')\n",
    "\n",
    "        for t in VALID_SOURCE_TABLES:\n",
    "            if f\"source_table = '{t}'\" in tgt:\n",
    "                source_table_counts[t] += 1\n",
    "\n",
    "        if 'SUM(' in tgt_upper:\n",
    "            intent_counts['sum'] += 1\n",
    "        elif 'AVG(' in tgt_upper:\n",
    "            intent_counts['average'] += 1\n",
    "        elif 'COUNT(' in tgt_upper:\n",
    "            intent_counts['count'] += 1\n",
    "        elif 'GROUP BY' in tgt_upper and ('SUM' in tgt_upper or 'COUNT' in tgt_upper):\n",
    "            intent_counts['compare'] += 1\n",
    "        elif 'DISTINCT' in tgt_upper:\n",
    "            intent_counts['list_categories'] += 1\n",
    "        elif \"document_type = 'file'\" in tgt:\n",
    "            intent_counts['list_files'] += 1\n",
    "        else:\n",
    "            intent_counts['query_data'] += 1\n",
    "\n",
    "        pairs.append(pair)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'üìä VALIDATION REPORT')\n",
    "print('=' * 60)\n",
    "print(f'Total pairs:  {len(pairs)}')\n",
    "print(f'Errors:       {len(errors)}')\n",
    "print()\n",
    "print('Source table distribution:')\n",
    "for t in sorted(source_table_counts, key=source_table_counts.get, reverse=True):\n",
    "    pct = source_table_counts[t] / len(pairs) * 100\n",
    "    print(f'  {t:20s} {source_table_counts[t]:5d} ({pct:.1f}%)')\n",
    "print()\n",
    "print('Intent distribution:')\n",
    "for intent in sorted(intent_counts, key=intent_counts.get, reverse=True):\n",
    "    pct = intent_counts[intent] / len(pairs) * 100\n",
    "    print(f'  {intent:20s} {intent_counts[intent]:5d} ({pct:.1f}%)')\n",
    "print()\n",
    "\n",
    "if errors:\n",
    "    print(f'‚ö†Ô∏è  First 10 errors:')\n",
    "    for e in errors[:10]:\n",
    "        print(f'  {e}')\n",
    "    print()\n",
    "\n",
    "if len(pairs) >= 4500 and len(errors) < len(pairs) * 0.05:\n",
    "    print(f'‚úÖ Data looks good! {len(pairs)} valid pairs ready.')\n",
    "elif len(pairs) > 0:\n",
    "    print(f'‚ö†Ô∏è  {len(pairs)} valid pairs. Error rate: {len(errors)/max(len(pairs),1)*100:.1f}%')\n",
    "else:\n",
    "    print('‚ùå No valid pairs found! Check your JSONL file.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 5: Clean + Merge (Custom + Spider + b-mc2 adapted)\n",
    "# ============================================================\n",
    "# Merges 3 data sources:\n",
    "#   1. Your custom 5k pairs (cleaned + validated)\n",
    "#   2. Spider dataset (~3k raw SQL pairs for general SQL knowledge)\n",
    "#   3. b-mc2/sql-create-context (~4k pairs adapted to our schema)\n",
    "#\n",
    "# The b-mc2 adaptation engine remaps general text-to-SQL pairs\n",
    "# to our single ai_documents table with JSONB metadata patterns.\n",
    "# This adds diversity (SUM, AVG, COUNT, GROUP BY) that the\n",
    "# custom dataset is missing.\n",
    "# ============================================================\n",
    "import json, re, hashlib, random\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "\n",
    "SPIDER_LIMIT = 3000\n",
    "BMC2_ADAPT_LIMIT = 4000  # how many b-mc2 pairs to adapt\n",
    "\n",
    "# ---- Utilities ----\n",
    "def normalize_sql(sql):\n",
    "    sql = sql.strip().rstrip(';').strip()\n",
    "    sql = re.sub(r'\\s+', ' ', sql)\n",
    "    return sql.lower()\n",
    "\n",
    "def sql_fingerprint(pair):\n",
    "    return hashlib.md5(normalize_sql(pair.get('target', '')).encode()).hexdigest()\n",
    "\n",
    "TYPO_FIXES = {\n",
    "    \"source_table = 'expenses'\": \"source_table = 'Expenses'\",\n",
    "    \"source_table = 'cashflow'\": \"source_table = 'CashFlow'\",\n",
    "    \"source_table = 'Cashflow'\": \"source_table = 'CashFlow'\",\n",
    "    \"source_table = 'cash_flow'\": \"source_table = 'CashFlow'\",\n",
    "    \"source_table = 'project'\": \"source_table = 'Project'\",\n",
    "    \"source_table = 'quotation'\": \"source_table = 'Quotation'\",\n",
    "    \"source_table = 'quotationitem'\": \"source_table = 'QuotationItem'\",\n",
    "    \"source_table = 'QuotationItems'\": \"source_table = 'QuotationItem'\",\n",
    "    \"source_table = 'Quotation_Item'\": \"source_table = 'QuotationItem'\",\n",
    "}\n",
    "\n",
    "def clean_pair(pair):\n",
    "    tgt = pair['target'].strip()\n",
    "    if not tgt.endswith(';'):\n",
    "        tgt += ';'\n",
    "    tgt = tgt.replace(';;', ';')\n",
    "    for wrong, right in TYPO_FIXES.items():\n",
    "        tgt = tgt.replace(wrong, right)\n",
    "    tgt = re.sub(r\"metadata->'(\\w+)'\", r\"metadata->>'\\1'\", tgt)\n",
    "    pair['target'] = tgt\n",
    "    return pair\n",
    "\n",
    "def validate_custom(pair):\n",
    "    inp = pair.get('input', '')\n",
    "    tgt = pair.get('target', '')\n",
    "    if not inp.startswith(SCHEMA_PREFIX):\n",
    "        return False\n",
    "    if not tgt.strip().upper().startswith('SELECT'):\n",
    "        return False\n",
    "    has_src = any(f\"source_table = '{t}'\" in tgt for t in VALID_SOURCE_TABLES)\n",
    "    if not has_src:\n",
    "        return False\n",
    "    if \"document_type = 'file'\" not in tgt and \"document_type = 'row'\" not in tgt:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# ============================================================\n",
    "# b-mc2 ADAPTATION ENGINE\n",
    "# Remaps general SQL to our ai_documents schema\n",
    "# ============================================================\n",
    "_ADAPT_SCHEMA = {\n",
    "    'Expenses': ['Category', 'Expenses', 'Name'],\n",
    "    'CashFlow': ['Type', 'Amount', 'Category'],\n",
    "    'Project': ['project_name', 'client_name', 'location', 'status'],\n",
    "    'Quotation': ['quote_number', 'status', 'total_amount', 'project_name'],\n",
    "    'QuotationItem': ['plate_no', 'dr_no', 'material', 'quarry_location',\n",
    "                      'truck_type', 'volume', 'line_total'],\n",
    "}\n",
    "_NUMERIC_KEYS = {'Expenses', 'Amount', 'total_amount', 'volume', 'line_total'}\n",
    "\n",
    "_ENTITY_POOLS = {\n",
    "    'project_names': [\n",
    "        'SJDM Residences', 'Francis Gays', 'Manila Tower Phase 2',\n",
    "        'Highway 5 Extension', 'Building C Phase 2', 'BGC Tower',\n",
    "        'Quezon City Mall', 'Makati Office', 'Taguig Hub',\n",
    "        'Cavite Housing Phase 1', 'Laguna Logistics Park',\n",
    "        'Bulacan Bypass Road', 'Cebu Business Center',\n",
    "    ],\n",
    "    'expense_categories': [\n",
    "        'Fuel', 'Labor', 'Materials', 'Equipment', 'Food',\n",
    "        'Transportation', 'Office Supplies', 'Cement', 'Steel',\n",
    "        'Sand', 'Gravel', 'Paint', 'Electrical', 'Plumbing',\n",
    "    ],\n",
    "    'cashflow_types': ['Income', 'Expense', 'Transfer', 'Loan', 'Payment'],\n",
    "    'cashflow_categories': [\n",
    "        'Client Payment', 'Material Purchase', 'Salary',\n",
    "        'Equipment Rental', 'Subcontractor Payment',\n",
    "    ],\n",
    "    'person_names': [\n",
    "        'Juan Dela Cruz', 'Maria Santos', 'Pedro Cruz',\n",
    "        'Jose Reyes', 'Ana Garcia', 'Carlos Mendoza',\n",
    "    ],\n",
    "    'client_names': ['DPWH', 'Ayala Corp', 'SM Prime Holdings', 'Megaworld', 'STI Construction'],\n",
    "    'locations': ['Quezon City', 'Makati', 'Taguig', 'Manila', 'Pasig', 'Cebu City'],\n",
    "    'materials': ['Gravel', 'Sand', 'Washed Sand', 'Crushed Rock', 'Fill Material', 'Limestone'],\n",
    "    'quarry_locations': ['Montalban', 'Teresa', 'Angono', 'San Mateo', 'Rodriguez'],\n",
    "    'plate_numbers': ['ABC-1234', 'XYZ-5678', 'DEF-9012', 'GHI-3456', 'JKL-7890'],\n",
    "    'dr_numbers': ['DR-001', 'DR-002', 'DR-2026-0042', 'DR-1234', 'DR-5001'],\n",
    "    'truck_types': ['6-Wheeler', '10-Wheeler', 'Dump Truck', 'Trailer', 'Mini Dump'],\n",
    "    'quote_numbers': ['QT-2026-001', 'QT-2026-002', 'QT-0042', 'Q-1234'],\n",
    "    'statuses_project': ['Active', 'Completed', 'On Hold', 'Cancelled'],\n",
    "    'statuses_quotation': ['Draft', 'Sent', 'Approved', 'Rejected'],\n",
    "}\n",
    "\n",
    "_POOL_MAP = {\n",
    "    ('Expenses', 'Category'): 'expense_categories',\n",
    "    ('Expenses', 'Name'): 'person_names',\n",
    "    ('CashFlow', 'Type'): 'cashflow_types',\n",
    "    ('CashFlow', 'Category'): 'cashflow_categories',\n",
    "    ('Project', 'project_name'): 'project_names',\n",
    "    ('Project', 'client_name'): 'client_names',\n",
    "    ('Project', 'location'): 'locations',\n",
    "    ('Project', 'status'): 'statuses_project',\n",
    "    ('Quotation', 'quote_number'): 'quote_numbers',\n",
    "    ('Quotation', 'status'): 'statuses_quotation',\n",
    "    ('Quotation', 'project_name'): 'project_names',\n",
    "    ('QuotationItem', 'plate_no'): 'plate_numbers',\n",
    "    ('QuotationItem', 'dr_no'): 'dr_numbers',\n",
    "    ('QuotationItem', 'material'): 'materials',\n",
    "    ('QuotationItem', 'quarry_location'): 'quarry_locations',\n",
    "    ('QuotationItem', 'truck_type'): 'truck_types',\n",
    "}\n",
    "\n",
    "# Intent classification from SQL patterns\n",
    "_AGG_RE = {\n",
    "    'sum': re.compile(r'\\bSUM\\s*\\(', re.IGNORECASE),\n",
    "    'avg': re.compile(r'\\bAVG\\s*\\(', re.IGNORECASE),\n",
    "    'count': re.compile(r'\\bCOUNT\\s*\\(', re.IGNORECASE),\n",
    "}\n",
    "_Q_INTENT = {\n",
    "    'sum': [r'\\btotal\\b', r'\\bsum\\b', r'\\bhow much\\b'],\n",
    "    'count': [r'\\bhow many\\b', r'\\bcount\\b', r'\\bnumber of\\b'],\n",
    "    'average': [r'\\baverage\\b', r'\\bavg\\b', r'\\bmean\\b'],\n",
    "    'list_files': [r'\\blist.*files?\\b', r'\\bshow.*files?\\b'],\n",
    "    'list_categories': [r'\\bdistinct\\b', r'\\bunique\\b', r'\\bcategories\\b'],\n",
    "    'compare': [r'\\bcompare\\b', r'\\bbreakdown\\b'],\n",
    "}\n",
    "\n",
    "def _classify(q, sql):\n",
    "    su = sql.upper()\n",
    "    if _AGG_RE['sum'].search(sql): return 'sum'\n",
    "    if _AGG_RE['avg'].search(sql): return 'average'\n",
    "    if _AGG_RE['count'].search(sql): return 'count'\n",
    "    if 'DISTINCT' in su and 'GROUP BY' not in su: return 'list_categories'\n",
    "    if 'GROUP BY' in su: return 'compare'\n",
    "    ql = q.lower()\n",
    "    for intent, pats in _Q_INTENT.items():\n",
    "        for p in pats:\n",
    "            if re.search(p, ql): return intent\n",
    "    return 'query_data'\n",
    "\n",
    "def _pick_table(intent):\n",
    "    if intent == 'list_files':\n",
    "        return random.choice(VALID_SOURCE_TABLES), 'file'\n",
    "    w = [0.35, 0.25, 0.15, 0.15, 0.10]\n",
    "    if intent in ('sum', 'average'): w = [0.40, 0.30, 0.0, 0.15, 0.15]\n",
    "    elif intent == 'count': w = [0.30, 0.20, 0.15, 0.15, 0.20]\n",
    "    return random.choices(VALID_SOURCE_TABLES, weights=w, k=1)[0], 'row'\n",
    "\n",
    "def _pick_key(tbl, numeric=False):\n",
    "    keys = _ADAPT_SCHEMA[tbl]\n",
    "    if numeric:\n",
    "        nk = [k for k in keys if k in _NUMERIC_KEYS]\n",
    "        if nk: return random.choice(nk)\n",
    "    return random.choice(keys)\n",
    "\n",
    "def _pick_val(tbl, key):\n",
    "    pool = _POOL_MAP.get((tbl, key))\n",
    "    if pool and pool in _ENTITY_POOLS:\n",
    "        return random.choice(_ENTITY_POOLS[pool])\n",
    "    if key in _NUMERIC_KEYS:\n",
    "        return str(random.choice([500, 1000, 2500, 5000, 10000, 25000]))\n",
    "    return 'sample value'\n",
    "\n",
    "def _friendly_tbl(t):\n",
    "    m = {'Expenses': 'expense', 'CashFlow': 'cash flow', 'Project': 'project',\n",
    "         'Quotation': 'quotation', 'QuotationItem': 'delivery'}\n",
    "    return m.get(t, t.lower())\n",
    "\n",
    "def _friendly_key(k):\n",
    "    m = {'Expenses': 'amount', 'Amount': 'amount', 'total_amount': 'total amount',\n",
    "         'volume': 'volume', 'line_total': 'line total', 'Category': 'category',\n",
    "         'Name': 'name', 'Type': 'type', 'project_name': 'project',\n",
    "         'client_name': 'client', 'location': 'location', 'status': 'status',\n",
    "         'quote_number': 'quote number', 'plate_no': 'plate number',\n",
    "         'dr_no': 'DR number', 'material': 'material',\n",
    "         'quarry_location': 'quarry', 'truck_type': 'truck type'}\n",
    "    return m.get(k, k.lower().replace('_', ' '))\n",
    "\n",
    "# Question templates per intent\n",
    "_TPL = {\n",
    "    'list_files': [\n",
    "        'show all {t} files', 'list {t} documents', 'what {t} files are available',\n",
    "        'display all {t} file records', 'get all {t} files',\n",
    "    ],\n",
    "    'count': [\n",
    "        'how many {t} entries have {k} as {v}', 'count {t} records where {k} is {v}',\n",
    "        'how many {t} rows with {k} {v}', 'total number of {t} entries for {k} {v}',\n",
    "    ],\n",
    "    'sum': [\n",
    "        'total {nk} for {t}', 'what is the total {nk} in {t}',\n",
    "        'how much {nk} for {fv} in {t}', 'sum of {nk} for {t} {fk} {fv}',\n",
    "        'calculate total {nk} in {t}',\n",
    "    ],\n",
    "    'average': [\n",
    "        'average {nk} for {t}', 'what is the average {nk} in {t}',\n",
    "        'mean {nk} across {t} records', 'avg {t} {nk}',\n",
    "    ],\n",
    "    'list_categories': [\n",
    "        'list all {k} values in {t}', 'what are the distinct {k} in {t}',\n",
    "        'show unique {k} for {t}', 'get distinct {k} from {t}',\n",
    "    ],\n",
    "    'compare': [\n",
    "        'compare {nk} by {gk} in {t}', 'breakdown of {nk} per {gk} for {t}',\n",
    "        '{t} {nk} grouped by {gk}', 'total {nk} per {gk} for {t}',\n",
    "    ],\n",
    "    'query_data': [\n",
    "        'show {t} data for {ks}', 'get {t} records with {ks}',\n",
    "        'display {t} {ks}', 'retrieve {ks} from {t}',\n",
    "    ],\n",
    "}\n",
    "\n",
    "def _adapt_one(question, sql):\n",
    "    \"\"\"Adapt a single general text-to-SQL pair to our schema.\"\"\"\n",
    "    intent = _classify(question, sql)\n",
    "    tbl, dtype = _pick_table(intent)\n",
    "    ft = _friendly_tbl(tbl)\n",
    "\n",
    "    if intent == 'list_files':\n",
    "        s = f\"SELECT id, file_name, project_name FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'file'\"\n",
    "        if random.random() < 0.4:\n",
    "            proj = random.choice(_ENTITY_POOLS['project_names'])\n",
    "            s += f\" AND project_name ILIKE '%{proj.lower()}%'\"\n",
    "        s += ' ORDER BY file_name;'\n",
    "        q = random.choice(_TPL['list_files']).format(t=ft)\n",
    "\n",
    "    elif intent == 'count':\n",
    "        k = _pick_key(tbl)\n",
    "        v = _pick_val(tbl, k)\n",
    "        s = f\"SELECT COUNT(*) AS count FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row'\"\n",
    "        if k not in _NUMERIC_KEYS and random.random() < 0.7:\n",
    "            s += f\" AND metadata->>'{k}' ILIKE '%{v.lower()}%'\"\n",
    "        s += ';'\n",
    "        q = random.choice(_TPL['count']).format(t=ft, k=_friendly_key(k), v=v)\n",
    "\n",
    "    elif intent == 'sum':\n",
    "        nk = _pick_key(tbl, numeric=True)\n",
    "        fk = _pick_key(tbl, numeric=False)\n",
    "        fv = _pick_val(tbl, fk)\n",
    "        s = f\"SELECT SUM((metadata->>'{nk}')::numeric) AS total FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row'\"\n",
    "        if fk != nk and fk not in _NUMERIC_KEYS and random.random() < 0.6:\n",
    "            s += f\" AND metadata->>'{fk}' ILIKE '%{fv.lower()}%'\"\n",
    "        if random.random() < 0.3:\n",
    "            proj = random.choice(_ENTITY_POOLS['project_names'])\n",
    "            s += f\" AND project_name ILIKE '%{proj.lower()}%'\"\n",
    "        s += ';'\n",
    "        q = random.choice(_TPL['sum']).format(t=ft, nk=_friendly_key(nk), fk=_friendly_key(fk), fv=fv)\n",
    "\n",
    "    elif intent == 'average':\n",
    "        nk = _pick_key(tbl, numeric=True)\n",
    "        s = f\"SELECT AVG((metadata->>'{nk}')::numeric) AS average FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row'\"\n",
    "        if random.random() < 0.4:\n",
    "            fk = _pick_key(tbl, numeric=False)\n",
    "            if fk != nk and fk not in _NUMERIC_KEYS:\n",
    "                fv = _pick_val(tbl, fk)\n",
    "                s += f\" AND metadata->>'{fk}' ILIKE '%{fv.lower()}%'\"\n",
    "        s += ';'\n",
    "        q = random.choice(_TPL['average']).format(t=ft, nk=_friendly_key(nk))\n",
    "\n",
    "    elif intent == 'list_categories':\n",
    "        k = _pick_key(tbl, numeric=False)\n",
    "        if k in _NUMERIC_KEYS:\n",
    "            k = _pick_key(tbl, numeric=False)\n",
    "        kl = k.lower().replace(' ', '_')\n",
    "        s = f\"SELECT DISTINCT metadata->>'{k}' AS {kl} FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row' ORDER BY {kl};\"\n",
    "        q = random.choice(_TPL['list_categories']).format(t=ft, k=_friendly_key(k))\n",
    "\n",
    "    elif intent == 'compare':\n",
    "        nk = _pick_key(tbl, numeric=True)\n",
    "        gk = _pick_key(tbl, numeric=False)\n",
    "        if gk == nk or gk in _NUMERIC_KEYS:\n",
    "            non_num = [x for x in _ADAPT_SCHEMA[tbl] if x not in _NUMERIC_KEYS]\n",
    "            gk = random.choice(non_num) if non_num else 'project_name'\n",
    "        if gk in ('project_name', 'file_name', 'source_table'):\n",
    "            s = f\"SELECT {gk}, SUM((metadata->>'{nk}')::numeric) AS total FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row' GROUP BY {gk} ORDER BY total DESC;\"\n",
    "        else:\n",
    "            gkl = gk.lower()\n",
    "            s = f\"SELECT metadata->>'{gk}' AS {gkl}, SUM((metadata->>'{nk}')::numeric) AS total FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row' GROUP BY {gkl} ORDER BY total DESC;\"\n",
    "        q = random.choice(_TPL['compare']).format(t=ft, nk=_friendly_key(nk), gk=_friendly_key(gk))\n",
    "\n",
    "    else:  # query_data\n",
    "        keys = _ADAPT_SCHEMA[tbl]\n",
    "        sel = random.sample(keys, min(random.randint(2, 4), len(keys)))\n",
    "        parts = [f\"metadata->>'{k}' AS {k.lower().replace(' ', '_')}\" for k in sel]\n",
    "        s = f\"SELECT {', '.join(parts)} FROM ai_documents WHERE source_table = '{tbl}' AND document_type = 'row'\"\n",
    "        fkeys = [k for k in keys if k not in _NUMERIC_KEYS]\n",
    "        if fkeys and random.random() < 0.7:\n",
    "            fk = random.choice(fkeys)\n",
    "            fv = _pick_val(tbl, fk)\n",
    "            s += f\" AND metadata->>'{fk}' ILIKE '%{fv.lower()}%'\"\n",
    "        if random.random() < 0.3:\n",
    "            proj = random.choice(_ENTITY_POOLS['project_names'])\n",
    "            s += f\" AND project_name ILIKE '%{proj.lower()}%'\"\n",
    "        s += ' LIMIT 25;'\n",
    "        ks = ', '.join(_friendly_key(k) for k in sel[:3])\n",
    "        q = random.choice(_TPL['query_data']).format(t=ft, ks=ks)\n",
    "\n",
    "    return {'input': SCHEMA_PREFIX + q, 'target': s}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: Clean custom pairs\n",
    "# ============================================================\n",
    "print('\\U0001f9f9 Step 1: Cleaning custom pairs...')\n",
    "cleaned = [clean_pair(dict(p)) for p in pairs]\n",
    "valid_custom = [p for p in cleaned if validate_custom(p)]\n",
    "n_invalid = len(cleaned) - len(valid_custom)\n",
    "print(f'   Valid: {len(valid_custom)}, Invalid: {n_invalid}')\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Download Spider dataset (raw SQL for general knowledge)\n",
    "# ============================================================\n",
    "print(f'\\n\\U0001f577\\ufe0f Step 2: Downloading Spider dataset (limit={SPIDER_LIMIT})...')\n",
    "spider_ds = load_dataset('spider', split='train')\n",
    "spider_pairs = []\n",
    "spider_seen = set()\n",
    "\n",
    "for ex in spider_ds:\n",
    "    q = ex.get('question', '')\n",
    "    sql = ex.get('query', '')\n",
    "    db = ex.get('db_id', '')\n",
    "    if not q or not sql:\n",
    "        continue\n",
    "    if not sql.strip().upper().startswith('SELECT'):\n",
    "        continue\n",
    "    tgt = sql.strip()\n",
    "    if not tgt.endswith(';'):\n",
    "        tgt += ';'\n",
    "    sfp = hashlib.md5(normalize_sql(tgt).encode()).hexdigest()\n",
    "    if sfp in spider_seen:\n",
    "        continue\n",
    "    spider_seen.add(sfp)\n",
    "    spider_pairs.append({\n",
    "        'input': f'tables: {db} | query: {q}',\n",
    "        'target': tgt\n",
    "    })\n",
    "    if len(spider_pairs) >= SPIDER_LIMIT:\n",
    "        break\n",
    "\n",
    "print(f'   Spider pairs loaded: {len(spider_pairs)}')\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Download + Adapt b-mc2/sql-create-context\n",
    "# ============================================================\n",
    "print(f'\\n\\U0001f504 Step 3: Downloading b-mc2/sql-create-context (adapt {BMC2_ADAPT_LIMIT})...')\n",
    "try:\n",
    "    bmc2_ds = load_dataset('b-mc2/sql-create-context', split='train')\n",
    "    print(f'   Downloaded: {len(bmc2_ds)} raw pairs')\n",
    "\n",
    "    # Filter to SELECT-only, then adapt\n",
    "    bmc2_candidates = []\n",
    "    for row in bmc2_ds:\n",
    "        q = str(row.get('question', '')).strip()\n",
    "        sql = str(row.get('answer', '')).strip()\n",
    "        if q and sql and sql.upper().startswith('SELECT'):\n",
    "            bmc2_candidates.append((q, sql))\n",
    "\n",
    "    print(f'   SELECT-only candidates: {len(bmc2_candidates)}')\n",
    "\n",
    "    # Shuffle and adapt up to limit\n",
    "    random.seed(123)\n",
    "    random.shuffle(bmc2_candidates)\n",
    "    bmc2_adapted = []\n",
    "    bmc2_intents = Counter()\n",
    "    for q, sql in bmc2_candidates[:BMC2_ADAPT_LIMIT * 2]:  # oversample, dedup later\n",
    "        adapted = _adapt_one(q, sql)\n",
    "        if adapted:\n",
    "            intent = _classify(q, sql)\n",
    "            bmc2_intents[intent] += 1\n",
    "            bmc2_adapted.append(adapted)\n",
    "        if len(bmc2_adapted) >= BMC2_ADAPT_LIMIT:\n",
    "            break\n",
    "\n",
    "    print(f'   Adapted pairs: {len(bmc2_adapted)}')\n",
    "    print(f'   Intent distribution:')\n",
    "    for intent, cnt in sorted(bmc2_intents.items(), key=lambda x: -x[1]):\n",
    "        print(f'     {intent:20s} {cnt:5d} ({cnt/max(len(bmc2_adapted),1)*100:.1f}%)')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'   \\u26a0\\ufe0f b-mc2 download failed: {e}')\n",
    "    print(f'   Continuing without b-mc2 (custom + Spider only)')\n",
    "    bmc2_adapted = []\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Merge all sources + Deduplicate\n",
    "# ============================================================\n",
    "print(f'\\n\\U0001f500 Step 4: Merging all sources + deduplicating...')\n",
    "all_merged = valid_custom + spider_pairs + bmc2_adapted\n",
    "seen_fps = set()\n",
    "deduped = []\n",
    "n_dupes = 0\n",
    "\n",
    "for p in all_merged:\n",
    "    fp = sql_fingerprint(p)\n",
    "    if fp not in seen_fps:\n",
    "        seen_fps.add(fp)\n",
    "        deduped.append(p)\n",
    "    else:\n",
    "        n_dupes += 1\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(deduped)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: Save merged file\n",
    "# ============================================================\n",
    "MERGED_FILE = '/kaggle/working/training_final.jsonl'\n",
    "with open(MERGED_FILE, 'w', encoding='utf-8') as f:\n",
    "    for p in deduped:\n",
    "        f.write(json.dumps(p, ensure_ascii=False) + '\\n')\n",
    "\n",
    "TRAINING_FILE = MERGED_FILE\n",
    "\n",
    "print()\n",
    "print('=' * 60)\n",
    "print('  CLEAN + MERGE REPORT')\n",
    "print('=' * 60)\n",
    "print(f'  Custom pairs (valid):    {len(valid_custom)}')\n",
    "print(f'  Custom pairs (invalid):  {n_invalid}')\n",
    "print(f'  Spider pairs (raw):      {len(spider_pairs)}')\n",
    "print(f'  b-mc2 adapted pairs:     {len(bmc2_adapted)}')\n",
    "print(f'  Duplicates removed:      {n_dupes}')\n",
    "print(f'  Total merged:            {len(deduped)}')\n",
    "print(f'  Output file:             {MERGED_FILE}')\n",
    "print('=' * 60)\n",
    "print()\n",
    "if len(deduped) >= 10000:\n",
    "    print(f'\\U0001f389 {len(deduped)} pairs ready for training! Great dataset size.')\n",
    "elif len(deduped) >= 5000:\n",
    "    print(f'\\u2705 {len(deduped)} pairs ready for training!')\n",
    "else:\n",
    "    print(f'\\u26a0\\ufe0f  Only {len(deduped)} pairs. Consider adding more custom data.')\n",
    "print(f'\\n\\U0001f4cc TRAINING_FILE updated to: {TRAINING_FILE}')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 6: Fine-tune T5 with LoRA (PEFT) -- bulletproof version\n",
    "# ============================================================\n",
    "# LoRA = Low-Rank Adaptation. Freezes base model, trains ~2.4M\n",
    "# adapter params (~0.3%). After training, merges back to normal T5.\n",
    "# ============================================================\n",
    "import json, time, gc, torch\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# --- Verify single GPU ---\n",
    "assert torch.cuda.device_count() == 1, (\n",
    "    f'Expected 1 GPU but found {torch.cuda.device_count()}! '\n",
    "    'Restart kernel and make sure Cell 1 has os.environ[CUDA_VISIBLE_DEVICES]=0'\n",
    ")\n",
    "print(f'GPU: {torch.cuda.get_device_name(0)} (single GPU mode)')\n",
    "\n",
    "# --- Config ---\n",
    "MODEL_NAME = 'gaussalgo/T5-LM-Large-text2sql-spider'\n",
    "OUTPUT_DIR = '/kaggle/working/t5-finetuned'\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 3e-5     # low LR for second-stage fine-tuning (prevents catastrophic forgetting)\n",
    "MAX_INPUT_LEN = 512\n",
    "MAX_TARGET_LEN = 256\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "# --- Load data ---\n",
    "print('Loading training data...')\n",
    "inputs, targets = [], []\n",
    "with open(TRAINING_FILE, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            pair = json.loads(line)\n",
    "            if 'input' in pair and 'target' in pair:\n",
    "                inputs.append(pair['input'])\n",
    "                targets.append(pair['target'])\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "dataset = Dataset.from_dict({'input': inputs, 'target': targets})\n",
    "split = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds, val_ds = split['train'], split['test']\n",
    "print(f'   Train: {len(train_ds)}, Validation: {len(val_ds)}')\n",
    "\n",
    "# --- Load model in float32 first, then LoRA ---\n",
    "print(f'Loading {MODEL_NAME}...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "print(f'   Base parameters: {base_model.num_parameters():,}')\n",
    "\n",
    "base_model.gradient_checkpointing_enable()\n",
    "print('   Gradient checkpointing: ON')\n",
    "\n",
    "print('Applying LoRA adapter...')\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=LORA_R, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=['q', 'v'],\n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# --- Tokenize ---\n",
    "# NOTE: Do NOT use padding='max_length' here -- let DataCollatorForSeq2Seq handle padding.\n",
    "# Only truncate. The collator will pad dynamically per batch and apply -100 masking.\n",
    "def tokenize(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['input'], max_length=MAX_INPUT_LEN,\n",
    "        truncation=True\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples['target'], max_length=MAX_TARGET_LEN,\n",
    "        truncation=True\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "print('Tokenizing...')\n",
    "tok_train = train_ds.map(tokenize, batched=True, remove_columns=['input', 'target'])\n",
    "tok_val = val_ds.map(tokenize, batched=True, remove_columns=['input', 'target'])\n",
    "\n",
    "# --- DIAGNOSTIC: Verify labels are NOT empty ---\n",
    "print('\\nüîç Label diagnostic (first 3 examples):')\n",
    "for i in range(min(3, len(tok_train))):\n",
    "    lbl = tok_train[i]['labels']\n",
    "    print(f'  Example {i}: {len(lbl)} label tokens, first 5: {lbl[:5]}')\n",
    "    if len(lbl) == 0:\n",
    "        raise ValueError(f'Example {i} has EMPTY labels! Check training data.')\n",
    "print()\n",
    "\n",
    "# --- Training args ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=2,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=0,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=1.0,\n",
    "    gradient_accumulation_steps=4,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_train,\n",
    "    eval_dataset=tok_val,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True),\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "steps_per_epoch = len(tok_train) // (BATCH_SIZE * 4)\n",
    "print(f'\\nStarting LoRA training: {EPOCHS} epochs, batch={BATCH_SIZE}, lr={LEARNING_RATE}')\n",
    "print(f'   Steps per epoch: ~{steps_per_epoch}')\n",
    "print(f'   Estimated time: ~{EPOCHS * steps_per_epoch * 0.5 / 60:.0f} minutes on single T4')\n",
    "print(f'   Single GPU: {torch.cuda.get_device_name(0)}\\n')\n",
    "\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "elapsed = (time.time() - start) / 60\n",
    "\n",
    "# --- Merge LoRA adapter back into base model ---\n",
    "print('\\nMerging LoRA adapter into base model...')\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# --- Save merged model ---\n",
    "save_path = f'{OUTPUT_DIR}/final'\n",
    "merged_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "model = merged_model\n",
    "\n",
    "print(f'\\nTraining complete in {elapsed:.1f} minutes!')\n",
    "print(f'   Model saved to: {save_path}')\n",
    "print(f'   LoRA adapter merged -- this is a normal T5 model now.')\n",
    "\n",
    "# --- AUTO-PUSH TO HUGGINGFACE (runs automatically after training) ---\n",
    "print('\\n' + '='*60)\n",
    "print('PUSHING TO HUGGINGFACE HUB...')\n",
    "print('='*60)\n",
    "try:\n",
    "    from huggingface_hub import login, HfApi\n",
    "    HF_TOKEN = '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'\n",
    "    HF_REPO = 't5-auggregates-text2sql'\n",
    "    login(token=HF_TOKEN)\n",
    "    api = HfApi()\n",
    "    whoami = api.whoami()\n",
    "    hf_username = whoami['name']\n",
    "    full_repo = f'{hf_username}/{HF_REPO}'\n",
    "    print(f'   Logged in as: {hf_username}')\n",
    "    print(f'   Repo: {full_repo}')\n",
    "    api.create_repo(HF_REPO, exist_ok=True, private=False)\n",
    "    print('   Uploading model files...')\n",
    "    merged_model.push_to_hub(full_repo)\n",
    "    tokenizer.push_to_hub(full_repo)\n",
    "    print(f'\\n‚úÖ Model pushed! https://huggingface.co/{full_repo}')\n",
    "    print(f'   Set in .env: T5_MODEL_PATH={full_repo}')\n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå HuggingFace push failed: {e}')\n",
    "    print('   Model is still saved locally at:', save_path)\n",
    "    print('   Run Cell 9B manually to retry the push.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 7: Evaluate on validation set\n",
    "# ============================================================\n",
    "import sqlparse\n",
    "import time\n",
    "\n",
    "print('üìä Evaluating on validation set...\\n')\n",
    "\n",
    "model.eval()\n",
    "device = model.device\n",
    "\n",
    "exact_matches = 0\n",
    "valid_sql = 0\n",
    "total_time = 0.0\n",
    "samples = []\n",
    "\n",
    "for idx in range(len(val_ds)):\n",
    "    inp = val_ds[idx]['input']\n",
    "    expected = val_ds[idx]['target']\n",
    "\n",
    "    encoded = tokenizer(inp, return_tensors='pt', max_length=MAX_INPUT_LEN, truncation=True, padding=True)\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "    t0 = time.time()\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=MAX_TARGET_LEN)\n",
    "    total_time += (time.time() - t0) * 1000\n",
    "\n",
    "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    if generated == expected:\n",
    "        exact_matches += 1\n",
    "\n",
    "    try:\n",
    "        parsed = sqlparse.parse(generated)\n",
    "        if parsed and parsed[0].get_type() and parsed[0].get_type().upper() == 'SELECT':\n",
    "            valid_sql += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if len(samples) < 15:\n",
    "        match = '‚úÖ' if generated == expected else '‚ùå'\n",
    "        samples.append((match, inp.split('query: ')[-1], expected, generated))\n",
    "\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f'  Evaluated {idx + 1}/{len(val_ds)}...')\n",
    "\n",
    "total = len(val_ds)\n",
    "em_acc = exact_matches / total * 100\n",
    "exec_acc = valid_sql / total * 100\n",
    "avg_ms = total_time / total\n",
    "\n",
    "print()\n",
    "print('=' * 60)\n",
    "print('  EVALUATION RESULTS')\n",
    "print('=' * 60)\n",
    "print(f'  Validation examples:   {total}')\n",
    "print(f'  Exact-match accuracy:  {em_acc:.1f}%')\n",
    "print(f'  Valid SQL rate:        {exec_acc:.1f}%')\n",
    "print(f'  Avg inference time:    {avg_ms:.1f} ms')\n",
    "print('=' * 60)\n",
    "print()\n",
    "\n",
    "if em_acc >= 70:\n",
    "    print('üéâ Great accuracy! Model is ready for deployment.')\n",
    "elif em_acc >= 50:\n",
    "    print('üëç Decent accuracy. Consider more training data or epochs.')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  Low accuracy. Check training data quality or try more epochs.')\n",
    "\n",
    "print()\n",
    "print('Sample predictions:')\n",
    "print('-' * 60)\n",
    "for match, question, expected, generated in samples[:10]:\n",
    "    print(f'{match} Q: {question}')\n",
    "    print(f'   Expected:  {expected[:100]}')\n",
    "    print(f'   Generated: {generated[:100]}')\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 8: Interactive test ‚Äî try your own questions\n",
    "# ============================================================\n",
    "\n",
    "SCHEMA_PREFIX_Q = 'tables: ai_documents (id, source_table, file_name, project_name, searchable_text, metadata, document_type) | query: '\n",
    "\n",
    "def generate_sql(question):\n",
    "    full_input = SCHEMA_PREFIX_Q + question\n",
    "    encoded = tokenizer(full_input, return_tensors='pt', max_length=MAX_INPUT_LEN, truncation=True, padding=True)\n",
    "    input_ids = encoded.input_ids.to(model.device)\n",
    "    attention_mask = encoded.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=MAX_TARGET_LEN)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "test_questions = [\n",
    "    'show all expense files',\n",
    "    'what are the total fuel expenses',\n",
    "    'how many labor entries are in project alpha',\n",
    "    'total cash flow amount for highway 5',\n",
    "    'show approved quotations for manila tower',\n",
    "    'total volume delivered for plate ABC-1234',\n",
    "    'list all active projects',\n",
    "    'average expense amount for materials',\n",
    "    'how many deliveries used 10-wheeler trucks',\n",
    "    'compare fuel costs between manila tower and building c',\n",
    "]\n",
    "\n",
    "print('üß™ Testing SQL generation:\\n')\n",
    "for q in test_questions:\n",
    "    sql = generate_sql(q)\n",
    "    print(f'Q: {q}')\n",
    "    print(f'‚Üí {sql}')\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 8B: Try your own question (edit and re-run)\n",
    "# ============================================================\n",
    "\n",
    "my_question = 'total expenses for SJDM project'  # <-- edit this!\n",
    "\n",
    "sql = generate_sql(my_question)\n",
    "print(f'Q: {my_question}')\n",
    "print(f'‚Üí {sql}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 9: Export model (zip for download)\n",
    "# ============================================================\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "FINAL_MODEL = '/kaggle/working/t5-finetuned/final'\n",
    "\n",
    "print('üì¶ Zipping model for download...')\n",
    "zip_path = shutil.make_archive('/kaggle/working/t5-finetuned-model', 'zip', FINAL_MODEL)\n",
    "print(f'   Size: {Path(zip_path).stat().st_size / 1024 / 1024:.0f} MB')\n",
    "\n",
    "print(f'\\n‚úÖ Model zipped at: {zip_path}')\n",
    "print('\\nüì• To download:')\n",
    "print('   1. Click the \"Output\" tab in the right panel')\n",
    "print('   2. Find t5-finetuned-model.zip')\n",
    "print('   3. Click the download icon')\n",
    "print()\n",
    "print('   Or save this notebook as a Kaggle Dataset to reuse the model.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CELL 9B: Push to HuggingFace Hub (optional)\n",
    "# ============================================================\n",
    "# Uncomment and fill in your details to push to HF Hub\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login(token='YOUR_HF_TOKEN')\n",
    "#\n",
    "# HF_REPO = 'your-username/t5-auggregates-text2sql'  # <-- change this!\n",
    "#\n",
    "# model.push_to_hub(HF_REPO)\n",
    "# tokenizer.push_to_hub(HF_REPO)\n",
    "# print(f'‚úÖ Pushed to https://huggingface.co/{HF_REPO}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù After Training\n",
    "\n",
    "**To use the fine-tuned model in production:**\n",
    "\n",
    "1. Download the zip from Cell 9 (Output tab) or use the HF Hub link from Cell 9B\n",
    "2. Extract to a folder on your server\n",
    "3. Set `T5_MODEL_PATH` environment variable to the extracted folder path\n",
    "4. The AI server will automatically use your fine-tuned model\n",
    "\n",
    "**Expected accuracy targets:**\n",
    "- Exact-match: 70%+ (good), 80%+ (great)\n",
    "- Valid SQL rate: 95%+\n",
    "\n",
    "**If accuracy is low:**\n",
    "- Check training data quality (run Cell 4 validation)\n",
    "- Try more epochs (change EPOCHS in Cell 6)\n",
    "- Try lower learning rate (1e-4 instead of 3e-4)\n",
    "- Add more diverse training pairs\n",
    "\n",
    "**Kaggle tips:**\n",
    "- GPU sessions last up to 12 hours\n",
    "- You get 30 hours/week of GPU time\n",
    "- Save your notebook to keep the output files"
   ]
  }
 ]
}